{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook converts VDJCounts.txt into allVDJRatios.csv. Calculates V-usage and J-usage from counts. Filters out Pseudogenes. Only extract patids that Sharon used (N=895)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import pickle\n",
    "import scipy\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counts_to_usage_df(counts_df, drop_families=[]):\n",
    "\n",
    "    # doesn't do anything now but could be used to extract only TRA, for example\n",
    "    df = counts_df[counts_df['transcript'].str.startswith(\"TR\")]\n",
    "\n",
    "    # split transcripts names (TRAJ24*01) into family (TRAJ24) and subtype (01)\n",
    "    transcript_family_subtype_df = df[\"transcript\"].str.split(\"*\", n = 1, expand = True).rename(columns={0:\"family\", 1:\"subtype\"})\n",
    "    df = df.copy()\n",
    "    df.loc[:,'count'] = df['count'].astype(int)\n",
    "    df.loc[:,\"family\"] = transcript_family_subtype_df[\"family\"]\n",
    "    df.loc[:,\"subtype\"] = transcript_family_subtype_df[\"subtype\"]\n",
    "    df = df.reset_index()\n",
    "    df = df[['patid', 'family', 'subtype', 'transcript', 'count']] # we don't need to the genotype information for now\n",
    "    \n",
    "    # drop any families (so that they are not included in total count)\n",
    "    if len(drop_families) > 0:\n",
    "        df = df[~df['family'].isin(drop_families)]\n",
    "    \n",
    "    # get total counts for every patient, every family (adding subtype counts together)\n",
    "    family_count_df = df.groupby([\"patid\", \"family\"]).sum().rename(columns={\"count\":\"family_count\"}).reset_index()\n",
    "\n",
    "    # take out the segment (AJ) out of the family (TRAJ1), and groupby patid+segment to get total AJ, total BJ, AV, BV for each patient\n",
    "    family_count_df['segment'] = family_count_df['family'].str.slice(start=2, stop=4)\n",
    "    segment_count_df = family_count_df.groupby([\"patid\", \"segment\"]).sum().rename(columns={\"family_count\":\"segment_count\"}).reset_index()\n",
    "\n",
    "    # merge the family count and segment count dfs, allowing us to calculate usage ratio\n",
    "    df_with_total = pd.merge(family_count_df, segment_count_df, how=\"inner\", on=[\"patid\", \"segment\"])\n",
    "    df_with_total[\"usage_ratio\"] = df_with_total[\"family_count\"]/df_with_total[\"segment_count\"]\n",
    "    # df_with_total[\"patid\"] = df_with_total[\"patid\"].apply(lambda x: int(x[2:])) # get rid of \"LD\" in front of patid\n",
    "    vdj_df = df_with_total[[\"patid\", \"family\", \"usage_ratio\"]]\n",
    "\n",
    "    # Filter out pseudogenes and non-functional genes\n",
    "    valid_TCR_genes = set()\n",
    "    with open(\"valid_TCR_genes.txt\", \"r\") as f:\n",
    "        for line in f:\n",
    "            valid_TCR_genes.add(line.strip())\n",
    "    vdj_df = vdj_df[vdj_df['family'].isin(valid_TCR_genes)]\n",
    "\n",
    "    # make both long and wide formats for the usage_ratio table\n",
    "    vdj_table = vdj_df.pivot(index=\"patid\", columns=\"family\", values=\"usage_ratio\").fillna(0)\n",
    "    vdj_table = vdj_table.reindex(sorted(vdj_table.columns), axis=1).fillna(0)\n",
    "    vdj_table = vdj_table.reset_index()\n",
    "\n",
    "    # only want patids in Sharon's paper, N=895, due to quality control\n",
    "    sharon_counts_df = pd.read_csv(\"gene_counts.tsv\", delimiter=\"\\t\")\n",
    "    sharon_counts_df = sharon_counts_df.reset_index()\n",
    "    sharon_ids = set(sharon_counts_df.columns[1:])\n",
    "    vdj_table = vdj_table[vdj_table['patid'].isin(sharon_ids)] \n",
    "\n",
    "    return vdj_df, vdj_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transcripts counts to usage\n",
    "def counts_to_usage_df(counts_df, drop_families=[]):\n",
    "    df = counts_df\n",
    "    # split transcripts names (TRAJ24*01) into family (TRAJ24) and subtype (01)\n",
    "    transcript_family_subtype_df = df[\"transcript\"].str.split(\"*\", n = 1, expand = True).rename(columns={0:\"family\", 1:\"subtype\"})\n",
    "    df = df.copy()\n",
    "    df.loc[:,'count'] = df['count'].astype(int)\n",
    "    df.loc[:,\"family\"] = transcript_family_subtype_df[\"family\"]\n",
    "    df.loc[:,\"subtype\"] = transcript_family_subtype_df[\"subtype\"]\n",
    "    df = df.reset_index()\n",
    "    df = df[['patid', 'family', 'subtype', 'transcript', 'count']] # we don't need to the genotype information for now\n",
    "    \n",
    "    # drop any families (so that they are not included in total count)\n",
    "    if len(drop_families) > 0:\n",
    "        df = df[~df['family'].isin(drop_families)]\n",
    "\n",
    "#     # Filter out pseudogenes and non-functional genes\n",
    "#     valid_TCR_genes = set()\n",
    "#     with open(\"valid_TCR_genes.txt\", \"r\") as f:\n",
    "#         for line in f:\n",
    "#             valid_TCR_genes.add(line.strip())\n",
    "#     valid_TCR_genes.add(\"TRAV8-5\")\n",
    "#     df = df[df['family'].isin(valid_TCR_genes)]\n",
    "    \n",
    "    # get total counts for every patient, every family (adding subtype counts together)\n",
    "    family_count_df = df.groupby([\"patid\", \"family\"]).sum().rename(columns={\"count\":\"family_count\"}).reset_index()\n",
    "\n",
    "    # take out the segment (AJ) out of the family (TRAJ1), and groupby patid+segment to get total AJ, total BJ, AV, BV for each patient\n",
    "    family_count_df['segment'] = family_count_df['family'].str.slice(start=2, stop=4)\n",
    "    segment_count_df = family_count_df.groupby([\"patid\", \"segment\"]).sum().rename(columns={\"family_count\":\"segment_count\"}).reset_index()\n",
    "\n",
    "    # merge the family count and segment count dfs, allowing us to calculate usage ratio\n",
    "    df_with_total = pd.merge(family_count_df, segment_count_df, how=\"inner\", on=[\"patid\", \"segment\"])\n",
    "    df_with_total[\"usage_ratio\"] = df_with_total[\"family_count\"]/df_with_total[\"segment_count\"]\n",
    "    # df_with_total[\"patid\"] = df_with_total[\"patid\"].apply(lambda x: int(x[2:])) # get rid of \"LD\" in front of patid\n",
    "    vdj_df = df_with_total[[\"patid\", \"family\", \"usage_ratio\"]]\n",
    "\n",
    "    # make both long and wide formats for the usage_ratio table\n",
    "    vdj_table = vdj_df.pivot(index=\"patid\", columns=\"family\", values=\"usage_ratio\").fillna(0)\n",
    "    vdj_table = vdj_table.reindex(sorted(vdj_table.columns), axis=1).fillna(0)\n",
    "    vdj_table = vdj_table.reset_index()\n",
    "\n",
    "    # only want patids in Sharon's paper, N=895, due to quality control\n",
    "    sharon_counts_df = pd.read_csv(\"gene_counts.tsv\", delimiter=\"\\t\")\n",
    "    sharon_counts_df = sharon_counts_df.reset_index()\n",
    "    sharon_ids = set(sharon_counts_df.columns[1:])\n",
    "    vdj_table = vdj_table[vdj_table['patid'].isin(sharon_ids)].set_index(\"patid\")\n",
    "\n",
    "    return vdj_df, vdj_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"VDJCounts.txt\", index_col=0, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n['TRAV13-1']\\n['TRAV13-1', 'TRAV17']\\n['TRAV13-1', 'TRAV17', 'TRAV13-2']\\n['TRAV13-1', 'TRAV17', 'TRAV13-2', 'TRAJ13']\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_drop = []\n",
    "\n",
    "\"\"\"\n",
    "['TRAV13-1']\n",
    "['TRAV13-1', 'TRAV17']\n",
    "['TRAV13-1', 'TRAV17', 'TRAV13-2']\n",
    "['TRAV13-1', 'TRAV17', 'TRAV13-2', 'TRAJ13']\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdj_df, vdj_table = counts_to_usage_df(df, drop_families=to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plotting gene expression\n",
    "# f, ax = plt.subplots(figsize=(5,50))\n",
    "# sns.boxplot(y=\"family\", x=\"usage_ratio\", data=vdj_df, fliersize=1.0)\n",
    "# plt.xlim((0,0.5))\n",
    "# plt.title(\"Protein Coding TCR Genes, without {}\".format(to_drop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save both long and wide formats to disk\n",
    "vdj_df.to_csv(\"DGN_vdj_usages.csv\", index=None)\n",
    "vdj_table.to_csv(\"DGN_vdj_usages_table.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## repurposed code used to plot before & after drop usages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd4_mean = vdj_table.mean().to_frame(\"cd4_mean\")\n",
    "cd8_mean = vdj_table_orig.mean().to_frame(\"cd8_mean\")\n",
    "merged_df = pd.merge(cd4_mean, cd8_mean, left_index=True, right_index=True, how=\"inner\").fillna(0.0) # merge on TCR\n",
    "merged_df = merged_df.reset_index()\n",
    "merged_df['segment'] = merged_df['family'].str.slice(start=0, stop=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'merged_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-69735ef2df5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#segment = \"TRAV\" # change this flag for different plots\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerged_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#plot_df = merged_df[merged_df['segment']==segment]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpearsonr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cd4_mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cd8_mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'merged_df' is not defined"
     ]
    }
   ],
   "source": [
    "#segment = \"TRAV\" # change this flag for different plots\n",
    "plot_df = merged_df\n",
    "#plot_df = merged_df[merged_df['segment']==segment]\n",
    "r, p = scipy.stats.pearsonr(plot_df['cd4_mean'], plot_df['cd8_mean'])\n",
    "\n",
    "sns.set()\n",
    "fig, ax = plt.subplots(figsize=(20,60))\n",
    "sns.scatterplot(x=\"cd4_mean\", y=\"cd8_mean\", hue=\"segment\", data=plot_df)\n",
    "plt.xlim(0.00, 0.06)\n",
    "plt.ylim(0.00, 0.06)\n",
    "ax.set_aspect('equal', 'box')\n",
    "plt.ylabel(\"No Dropped\")\n",
    "plt.xlabel(\"Dropped {}\".format(to_drop))\n",
    "plt.title(\"Pearson's R: {:4f}, (two-tailed p-value {:4f})\".format(r, p))\n",
    "\n",
    "lims = [\n",
    "    np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n",
    "    np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n",
    "]\n",
    "# now plot both limits against eachother\n",
    "ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "\n",
    "def label_point(x, y, val, ax):\n",
    "    a = pd.concat({'x': x, 'y': y, 'val': val}, axis=1)\n",
    "    for i, point in a.iterrows():\n",
    "        if abs(point['x'] - point['y']) > 0.001:\n",
    "        #if str(point['val']) in ['TRAV23/DV6', 'TRAV13-1', 'TRAV10-1', 'TRAV17']:\n",
    "            ax.text(point['x']+.001, point['y'], str(point['val']))\n",
    "\n",
    "label_point(plot_df['cd4_mean'], plot_df['cd8_mean'], plot_df['family'], plt.gca())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
